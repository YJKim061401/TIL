# 회귀

분류보다는 회귀를 더 많이 활용

왜?대부분의 기업에서 사용하는 예측이 수치적 예측 e.g. 다음달 매출액이 얼마 

#### 독립변수는 '피처' 

#### 종속변수는 '결정값'

#### 회귀계수는 독립변수(피처)값에 영향을 미치는 것 

#### 최적의 회귀계수를 찾아 예측하는 방법 

### 회귀 평가 지표

1. MSE 
   * 실제값과 예측값의 차이를 제곱해서 평균
2. RMSE
   * MSE의 값이 오류의 제곱을 구하므로 실제 오류 평균보다 커지는 특성 그래서 MSE에 루트 씌움
   * 사이킷런에서는 제공 X
   * 따로 MSE에 제곱근 씌워 계산하는 함수 직접 구현해야함
3. R squared
   * 분산 기반으로 예측 성능 평가
   * 실제 값의 분산 대비 예측 값의 분산 비율을 지표로
   * 1에 가까울수록 예측 정확도 높음 



### 편항-분산 트레이드오프 (Bias-Variance Trade off)

#### 편향 : 한 방향으로 치우치는 것 (정확한 결과에 집중 또는 벗어나는 것)



#### 분산 : 분포도



일반적으로 편향과 분산은 한쪽이 높으면 한쪽이 낮아지는 경향이 있음

즉, 편향이 높으면 분산은 낮아지고 -->  (과소적합)

반대로 분산이 높으면 편향이 낮아짐 --> (과적합)



편향과 분산의 관계에 따른 전체 오류값의 변화

편향이 너무 높으면 전체 오류가 높음

편향을 낮추면 동시에 분산이 높아지고 전체 오류도 낮아지게 됨

골디락스 지점 : 편향을 낮추고 분산을 높이면서 전체 오류가 낮아지는 지점

골디락스 지점을 통과하면서 분산을 지속적으로 높이면

전체 오류값이 오히려 증가하면서 예측 성능이 다시 저하됨